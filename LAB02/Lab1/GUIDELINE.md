**Lab 1: Benchmark PostgreSQL vs Redis**  
**T·ªïng ƒëi·ªÉm:** 100  
**Th·ªùi gian:** 2 tu·∫ßn

**Late Policy:** Lab c√≥ h·∫°n ch√≥t v√† ph·∫£i ƒë∆∞·ª£c n·ªôp tr∆∞·ªõc **11:59 PM** v√†o ƒë√∫ng ng√†y ƒë·∫øn h·∫°n. N·∫øu n·ªôp tr∆∞·ªõc **1:00 AM** c·ªßa ng√†y h√¥m sau, b√†i s·∫Ω v·∫´n ƒë∆∞·ª£c ch·∫•p nh·∫≠n nh∆∞ng **b·ªã tr·ª´ 5%** ƒëi·ªÉm.

---

## **Lab overview**

M·ª•c ti√™u lab l√† so s√°nh hi·ªáu nƒÉng gi·ªØa **disk-based database** (PostgreSQL) v√† **in-memory database** (Redis) trong context c·ªßa real-time systems.

C√¢u h·ªèi ch√≠nh:
* PostgreSQL vs Redis: Latency kh√°c nhau bao nhi√™u?
* Batch operations c√≥ gi√∫p gi·∫£m latency kh√¥ng?
* Trade-off: Durability (PostgreSQL) vs Speed (Redis)?

Deliverable:
* Benchmark code (Python) + Docker setup
* Log files: latency measurements
* B√°o c√°o 4-6 trang v·ªõi plots

---

## **Part 1 ‚Äî Theory & Motivation**

**M·ª•c ti√™u:** Hi·ªÉu ki·∫øn tr√∫c disk-based vs in-memory databases.

**Sinh vi√™n c·∫ßn l√†m v√† n·ªôp:**

* **Disk-based DB (PostgreSQL)**:
  - Data l∆∞u tr√™n disk (HDD/SSD)
  - Write-Ahead Logging (WAL) cho durability
  - Write path: Client ‚Üí Parse SQL ‚Üí Write WAL ‚Üí fsync ‚Üí Update buffer pool
  - Latency sources: **Disk fsync (5-15ms HDD, 0.1-1ms SSD)**, lock contention, connection overhead
  - ACID guarantees: Atomicity, Consistency, Isolation, Durability

* **In-memory DB (Redis)**:
  - All data in RAM
  - Optional persistence: RDB snapshot, AOF (Append-Only File)
  - Write path: Client ‚Üí Parse command ‚Üí Update in-memory ‚Üí (Optional) AOF ‚Üí Return
  - Latency sources: Network I/O (~0.1ms), command execution (<1ms)
  - BASE model: Basically Available, Soft-state, Eventually consistent

* **Use cases**:
  - PostgreSQL: Persistent critical data (transactions, audit logs)
  - Redis: High-frequency telemetry, session cache, real-time leaderboards

* **Hypothesis**:
  - Redis **10-50x** faster than PostgreSQL for writes
  - Batch operations reduce latency per record
  - PostgreSQL has higher variance (jitter)

**B·∫±ng ch·ª©ng b·∫Øt bu·ªôc:**

* B·∫£ng so s√°nh: PostgreSQL vs Redis (storage, durability, latency, ACID/BASE)
* Diagram: Write path cho PostgreSQL v√† Redis

---

## **Part 2 ‚Äî Environment Setup**

**M·ª•c ti√™u:** D·ª±ng PostgreSQL v√† Redis qua Docker, chu·∫©n b·ªã benchmark scripts.

**Sinh vi√™n c·∫ßn l√†m v√† n·ªôp:**

* **Docker Compose setup**:
  ```yaml
  # docker-compose.yml
  version: '3.8'
  services:
    postgres:
      image: postgres:14
      environment:
        POSTGRES_USER: testuser
        POSTGRES_PASSWORD: testpass
        POSTGRES_DB: testdb
      ports:
        - "5432:5432"
    
    redis:
      image: redis:7
      ports:
        - "6379:6379"
  ```

* **Start containers**:
  ```bash
  docker-compose up -d
  # Check: docker ps
  ```

* **PostgreSQL schema**:
  ```sql
  CREATE TABLE logs (
      id SERIAL PRIMARY KEY,
      timestamp DOUBLE PRECISION,
      sensor_id INTEGER,
      value DOUBLE PRECISION
  );
  ```

* **Redis schema** (key-value):
  ```
  Key: log:<id>
  Value: JSON string {"timestamp": ..., "sensor_id": ..., "value": ...}
  ```

* **Python dependencies**:
  ```bash
  pip install psycopg2-binary redis matplotlib pandas
  ```

**B·∫±ng ch·ª©ng b·∫Øt bu·ªôc:**

* `docker-compose.yml` file
* `schema.sql` (PostgreSQL table creation)
* `requirements.txt` (Python packages)
* Commands ƒë·ªÉ start v√† verify containers

---

## **Part 3 ‚Äî Benchmark Implementation**

**M·ª•c ti√™u:** Vi·∫øt script benchmark single writes v√† batch writes.

**Sinh vi√™n c·∫ßn l√†m v√† n·ªôp:**

* **Workloads**:
  1. **Single write** (1000 records): 1 record ‚Üí 1 INSERT/SET ‚Üí 1 commit
  2. **Batch write** (1000 records): 100 records ‚Üí 1 batch INSERT/MSET ‚Üí 1 commit

* **PostgreSQL benchmark**:
  ```python
  import psycopg2
  import time
  
  conn = psycopg2.connect("postgresql://testuser:testpass@localhost/testdb")
  cur = conn.cursor()
  
  # Single write
  latencies = []
  for i in range(1000):
      t1 = time.time()
      cur.execute("INSERT INTO logs VALUES (%s, %s, %s, %s)", 
                  (i, time.time(), i%10, i*0.1))
      conn.commit()
      t2 = time.time()
      latencies.append((t2-t1)*1000)  # ms
  
  # Metrics
  print(f"Avg: {np.mean(latencies):.2f}ms")
  print(f"p99: {np.percentile(latencies, 99):.2f}ms")
  print(f"Max: {np.max(latencies):.2f}ms")
  ```

* **Redis benchmark**:
  ```python
  import redis
  import time
  
  r = redis.Redis(host='localhost', port=6379)
  
  # Single write
  latencies = []
  for i in range(1000):
      t1 = time.time()
      r.set(f"log:{i}", json.dumps({"timestamp": time.time(), "sensor_id": i%10, "value": i*0.1}))
      t2 = time.time()
      latencies.append((t2-t1)*1000)
  
  # Metrics (same as above)
  ```

* **Batch benchmarks**: Similar, nh∆∞ng commit sau m·ªói 100 records

* **Metrics to collect**:
  - Latency: avg, p50, p95, p99, max
  - Jitter: standard deviation
  - Throughput: records/second

**B·∫±ng ch·ª©ng b·∫Øt bu·ªôc:**

* `benchmark.py`: Full script v·ªõi 4 functions (PG single, PG batch, Redis single, Redis batch)
* Command: `python3 benchmark.py > benchmark_results.log`
* Log file v·ªõi latency measurements

---

## **Part 4 ‚Äî Results & Analysis**

**M·ª•c ti√™u:** Ph√¢n t√≠ch k·∫øt qu·∫£, visualize, v√† gi·∫£i th√≠ch findings.

**Sinh vi√™n c·∫ßn l√†m v√† n·ªôp:**

* **Results table**:
  | Database | Operation | Avg (ms) | p99 (ms) | Max (ms) | Jitter (stddev) | Throughput (ops/s) |
  |----------|-----------|----------|----------|----------|-----------------|---------------------|
  | PostgreSQL | Single | 12.5 | 24.3 | 52.1 | 5.8 | 80 |
  | PostgreSQL | Batch | 4.5 | 8.7 | 15.2 | 2.1 | 222 |
  | Redis | Single | 0.8 | 1.8 | 3.2 | 0.3 | 1250 |
  | Redis | Batch | 1.2 | 2.1 | 4.5 | 0.5 | 833 |

  **Observations**:
  - Redis **15-16x faster** than PostgreSQL (single writes)
  - PostgreSQL benefits t·ª´ batching (2.8x improvement)
  - Redis batching slightly slower (pipeline overhead)

* **Visualization 1: CDF plot**
  - X-axis: Latency (ms)
  - Y-axis: Cumulative probability
  - 4 curves: PG single, PG batch, Redis single, Redis batch
  - **Observation**: Redis distribution t·∫≠p trung, PostgreSQL c√≥ long tail

* **Visualization 2: Bar chart**
  - X-axis: Database + Operation
  - Y-axis: p99 latency (ms)
  - **Observation**: PostgreSQL p99 = 24.3ms, Redis p99 = 1.8ms

* **Root cause analysis**:
  - **Why PostgreSQL slow?**
    1. Disk fsync: ~10ms per commit
    2. WAL write overhead
    3. Connection pooling overhead (if not used)
  
  - **Why Redis fast?**
    1. RAM access: ~100ns (vs 10ms disk)
    2. Simple protocol: SET command simpler than SQL parsing
    3. Single-threaded: No lock contention
  
  - **Why PostgreSQL batching helps?**
    - 1 commit for 100 records vs 100 commits
    - Amortized fsync overhead: 10ms / 100 = 0.1ms per record
  
  - **Why Redis batching slower?**
    - Pipeline overhead: packing/unpacking commands
    - Still faster than PostgreSQL single writes

* **Trade-offs**:
  | Aspect | PostgreSQL | Redis | Winner for RT? |
  |--------|------------|-------|----------------|
  | Latency | 10-50ms | <1ms | ‚úÖ Redis |
  | Durability | Guaranteed | Optional | PostgreSQL |
  | Query complexity | SQL (joins, aggregates) | Simple KV | PostgreSQL |
  | Consistency | ACID (strong) | Eventual | PostgreSQL |
  | Memory footprint | Small (disk) | Large (RAM) | PostgreSQL |

* **Production recommendation**:
  ```
  Sensor ‚Üí Redis (buffer, <1ms) ‚Üí Background worker ‚Üí PostgreSQL (persistence)
           Fast write for control                     Durable storage for audit
  ```

**B·∫±ng ch·ª©ng b·∫Øt bu·ªôc:**

* Results table (4 rows √ó 6 metrics)
* 2 plots: CDF + bar chart
* 10-15 d√≤ng ph√¢n t√≠ch root cause
* Trade-off table
* Architecture diagram cho hybrid approach

---

## **What to turn in**

### 1. **PDF Report** (t√™n file: `Lab1_Report_<MSSV>_<HoTen>.pdf`)

B√°o c√°o d√†i **4-6 trang**.

**B√°o c√°o ph·∫£i g·ªìm:**

* **a. Title page** [kh√¥ng t√≠nh ƒëi·ªÉm]

* **b. Introduction & Theory** [20 points]
  - Disk-based vs In-memory architectures
  - ACID vs BASE
  - Write path comparison (diagram)
  - Hypothesis: Redis 10-50x faster

* **c. Methodology** [15 points]
  - Docker Compose setup (PostgreSQL + Redis)
  - Schema design (SQL table, Redis keys)
  - Benchmark workloads: Single vs Batch (1000 records)
  - Metrics: latency (avg/p99/max), jitter, throughput

* **d. Results** [30 points]
  - **Table 1**: Performance comparison (4 rows √ó 6 metrics)
  - **Figure 1**: CDF plot (4 curves)
  - **Figure 2**: p99 latency bar chart
  - Description (3-5 d√≤ng)

* **e. Analysis** [25 points]
  - Root cause: Why PostgreSQL slow (fsync), why Redis fast (RAM)
  - Batching impact: PG 2.8x improvement, Redis slight degradation
  - Theoretical vs measured: Expected ~10ms fsync ‚Üí measured 12.5ms ‚úì
  - Trade-offs: Latency vs Durability vs Query complexity
  - Hybrid architecture recommendation (diagram)

* **f. Conclusion** [10 points]
  - Summary: Redis 15x faster, PostgreSQL more durable
  - Use case: Redis for hot path, PostgreSQL for cold storage
  - Limitations: Test tr√™n localhost (no network latency), single-threaded client
  - Future work: Test v·ªõi concurrent clients, replication overhead

### 2. **Code & Data Package**

**B·∫Øt bu·ªôc c√≥:**

* `docker-compose.yml`: Database containers
* `schema.sql`: PostgreSQL table creation
* `benchmark.py`: Full benchmark script
* `requirements.txt`: Python dependencies
* `README.md`: Setup v√† run instructions
* `logs/`: Benchmark results (CSV ho·∫∑c JSON)
* `plots/`: CDF, bar chart (PNG ho·∫∑c PDF)

### 3. **Reproducibility**

* `run_benchmark.sh`: One-command ƒë·ªÉ ch·∫°y t·∫•t c·∫£
  ```bash
  #!/bin/bash
  docker-compose up -d
  sleep 5  # wait for DB ready
  python3 benchmark.py > results.log
  python3 plot_results.py
  echo "Done! Check plots/ and results.log"
  ```

---

## **Grading Rubric**

| Section | Points | Criteria |
|---------|--------|----------|
| **Theory** | 20 | Disk vs in-memory, ACID vs BASE, write path diagram |
| **Methodology** | 15 | Docker setup, schema, workloads, metrics |
| **Results** | 30 | Table + 2 plots (CDF + bar chart) |
| **Analysis** | 25 | Root cause, batching, trade-offs, hybrid architecture |
| **Conclusion** | 10 | Summary, use cases, limitations |
| **Total** | **100** | |

**Bonus** (up to +10):
* Test v·ªõi SSD vs HDD cho PostgreSQL: +3
* Connection pooling (PgBouncer) impact: +4
* Concurrent clients benchmark: +3

---

## **Tips & Common Pitfalls**

### ‚úÖ Do's:
* **Warm-up**: Ch·∫°y 100 records tr∆∞·ªõc ƒë·ªÉ warm cache
* **Multiple runs**: Ch·∫°y 3 l·∫ßn, l·∫•y median
* **fsync check**: PostgreSQL default synchronous_commit = on (ensure durability)
* **Redis persistence**: Test v·ªõi AOF enabled v√† disabled

### ‚ùå Don'ts:
* **Kh√¥ng test tr√™n laptop**: Disk-based DB sensitive to disk speed
* **Kh√¥ng qu√™n connection pooling**: PostgreSQL connection overhead ~10ms
* **Kh√¥ng so s√°nh unfairly**: Redis no persistence vs PostgreSQL fsync (apples to oranges)

### üîß Debugging:
* **PostgreSQL slow connection**: Use connection pooling (PgBouncer)
* **Redis timeout**: Check `redis.conf` timeout settings
* **Latency spike**: Check Docker resource limits (`docker stats`)

---

## **References**

1. PostgreSQL Documentation. (2024). *Write-Ahead Logging (WAL)*. https://www.postgresql.org/docs/current/wal-intro.html

2. Redis Documentation. (2024). *Persistence*. https://redis.io/docs/management/persistence/

3. Ramamritham, K., & Chrysanthis, P. K. (1996). *Advances in Real-Time Database Systems*. Kluwer Academic Publishers.

4. Corbett, J. C., et al. (2013). *Spanner: Google's Globally Distributed Database*. ACM TOCS, 31(3).

---

**Good luck!** üíæ
